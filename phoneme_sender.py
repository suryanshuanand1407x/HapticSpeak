import whisper
import time
import pyaudio
import wave
import os
import json
import re

# ----------- CONFIGURATION -----------
DURATION = 4  # Seconds to record
WHISPER_MODEL = "base"  # Or "tiny" for faster results
WAV_FILENAME = "000010-0014.wav"
SOUND_FOLDER = "phoneme_sounds"  # Folder containing AH.wav, B.wav, etc.
VIBRATION_MAP_FILE = "english_phoneme_vibration_map.json"
# --------------------------------------

# Initialize Whisper model
model = whisper.load_model(WHISPER_MODEL)

# Load vibration mapping
def load_vibration_map():
    try:
        with open(VIBRATION_MAP_FILE, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå Vibration map file not found: {VIBRATION_MAP_FILE}")
        return {}

vibration_map = load_vibration_map()

# Record microphone input
def record_audio(filename=WAV_FILENAME, duration=DURATION):
    RATE = 16000
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1

    audio = pyaudio.PyAudio()
    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    print("üéôÔ∏è Recording...")
    frames = []
    for _ in range(0, int(RATE / CHUNK * duration)):
        data = stream.read(CHUNK)
        frames.append(data)

    print("‚úÖ Recording complete.")
    stream.stop_stream()
    stream.close()
    audio.terminate()

    wf = wave.open(filename, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(audio.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

# Transcribe audio using Whisper
def transcribe_audio(filename=WAV_FILENAME):
    result = model.transcribe(filename)
    text = result["text"]
    print(f"üìù Transcript: {text}")
    return text

# Simple text to ARPAbet phoneme mapping (basic implementation)
def text_to_phonemes(text):
    # Basic word-to-phoneme mapping for common English words
    word_to_phonemes = {
        "overall": ["OW", "V", "ER", "AO", "L"],
        "it's": ["IH", "T", "S"],
        "just": ["JH", "AH", "S", "T"],
        "important": ["IH", "M", "P", "AO", "R", "T", "AH", "N", "T"],
        "that": ["DH", "AE", "T"],
        "you": ["Y", "UW"],
        "know": ["N", "OW"],
        "you're": ["Y", "UH", "R"],
        "not": ["N", "AA", "T"],
        "alone": ["AH", "L", "OW", "N"],
        "and": ["AE", "N", "D"],
        "we're": ["W", "IH", "R"],
        "here": ["HH", "IH", "R"],
        "to": ["T", "UW"],
        "help": ["HH", "EH", "L", "P"]
    }
    
    # Clean and split text into words
    words = re.findall(r'\b\w+\b', text.lower())
    all_phonemes = []
    
    for word in words:
        if word in word_to_phonemes:
            all_phonemes.extend(word_to_phonemes[word])
            print(f"üî§ {word} -> {word_to_phonemes[word]}")
        else:
            print(f"‚ö†Ô∏è Unknown word: {word}")
    
    print(f"üî° All phonemes: {all_phonemes}")
    return all_phonemes

# Generate vibration pattern for a phoneme
def generate_vibration_for_phoneme(phoneme):
    if phoneme in vibration_map:
        vibration_data = vibration_map[phoneme]
        waveform = vibration_data["waveform"]
        library = vibration_data["library"]
        print(f"üî¥ VIBRATION: {phoneme} -> Waveform: {waveform}, Library: {library}")
        
        # Here you would send the vibration command to your haptic device
        # For now, we'll just print the command that would be sent
        print(f"   üì° Command: SET_VIBRATION(waveform={waveform}, library={library})")
        return {"phoneme": phoneme, "waveform": waveform, "library": library}
    else:
        print(f"‚ö†Ô∏è No vibration pattern found for phoneme: {phoneme}")
        return None

# Main workflow
def main():
    # Use existing WAV file from phoneme_sounds directory
    wav_file = os.path.join(SOUND_FOLDER, WAV_FILENAME)
    if os.path.exists(wav_file):
        print(f"üìÅ Using existing file: {wav_file}")
        text = transcribe_audio(wav_file)
        phonemes = text_to_phonemes(text)
        
        print(f"\nüéØ GENERATING VIBRATION SEQUENCE:")
        print("=" * 50)
        
        vibration_sequence = []
        for phoneme in phonemes:
            vibration_data = generate_vibration_for_phoneme(phoneme)
            if vibration_data:
                vibration_sequence.append(vibration_data)
            time.sleep(0.1)  # Small delay between phonemes
            
        print("=" * 50)
        print(f"‚úÖ Generated {len(vibration_sequence)} vibration commands")
        
        # Summary of the complete vibration sequence
        print(f"\nüìã COMPLETE VIBRATION SEQUENCE:")
        for i, vib in enumerate(vibration_sequence):
            print(f"  {i+1:2d}. {vib['phoneme']:2s} -> W:{vib['waveform']:2d} L:{vib['library']}")
            
    else:
        print(f"‚ùå File not found: {wav_file}")

if __name__ == "__main__":
    main()